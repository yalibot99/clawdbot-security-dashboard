#!/usr/bin/env python3
"""
Flask dashboard for Clawdbot security visualization.
Enhanced version with attack simulations and real-time data.
Uses Censys API for discovering exposed Clawdbot installations.
Background scheduler for hourly auto-scans.
"""

import json
import os
import random
import requests
import logging
from flask import Flask, render_template, jsonify, request
from datetime import datetime
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
import shutil

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# Censys API configuration
CENSYS_API_ID = os.environ.get('CENSYS_API_ID', '')
CENSYS_API_SECRET = os.environ.get('CENSYS_API_SECRET', '')

# Timeout for fingerprinting requests
REQUEST_TIMEOUT = 3

def ensure_data_file():
    """Ensure results.json exists in static/data folder."""
    data_dir = 'static/data'
    data_file = os.path.join(data_dir, 'results.json')
    
    os.makedirs(data_dir, exist_ok=True)
    
    scraper_file = 'scraper/results.json'
    if os.path.exists(scraper_file) and not os.path.exists(data_file):
        shutil.copy(scraper_file, data_file)
    
    return data_file

def load_results():
    """Load scan results."""
    data_file = ensure_data_file()
    if os.path.exists(data_file):
        with open(data_file) as f:
            data = json.load(f)
            if data:  # Only return if file has actual data
                return data
    
    # Return demo/sample data if no real data exists
    return [
        {
            "ip": "192.168.1.100",
            "port": 3000,
            "risk_score": 85,
            "location": {"city": "Tel Aviv", "country_name": "Israel", "lat": 32.0853, "lng": 34.7818},
            "vulns": ["exposed_api", "no_auth"],
            "service": "Clawdbot Web UI",
            "timestamp": datetime.now().isoformat(),
            "source": "demo"
        },
        {
            "ip": "10.0.0.55",
            "port": 18789,
            "risk_score": 92,
            "location": {"city": "New York", "country_name": "United States", "lat": 40.7128, "lng": -74.0060},
            "vulns": ["exposed_api", "exposed_terminal", "no_auth"],
            "service": "Clawdbot Gateway",
            "timestamp": datetime.now().isoformat(),
            "source": "demo"
        },
        {
            "ip": "172.16.0.23",
            "port": 8080,
            "risk_score": 45,
            "location": {"city": "Berlin", "country_name": "Germany", "lat": 52.5200, "lng": 13.4050},
            "vulns": ["outdated_version"],
            "service": "Clawdbot Web UI",
            "timestamp": datetime.now().isoformat(),
            "source": "demo"
        }
    ]

def calculate_risk_score(vulns):
    """Calculate risk score based on vulnerabilities."""
    base_score = 50
    
    vuln_weights = {
        'no_auth': 25,
        'exposed_api': 15,
        'exposed_terminal': 30,
        'default_creds': 20,
        'outdated_version': 10,
        'missing_rate_limiting': 5,
        'gateway_exposed': 20,
        'browser_control_exposed': 15
    }
    
    score = base_score
    for vuln in vulns:
        score += vuln_weights.get(vuln, 5)
    
    return min(100, max(0, score))

def fingerprint_clawdbot(ip, port):
    """
    Actively fingerprint a service to verify it's Clawdbot.
    Returns (is_clawdbot, vulns, service_info) tuple.
    """
    base_url = f"http://{ip}:{port}"
    vulns = []
    service_info = {}
    
    # Check 1: Gateway API health endpoint
    try:
        response = requests.get(
            f"{base_url}/api/health",
            timeout=REQUEST_TIMEOUT
        )
        if response.status_code == 200:
            data = response.json()
            if data.get('status') == 'ok':
                vulns.append('exposed_api')
                service_info['gateway'] = True
    except:
        pass
    
    # Check 2: Gateway status endpoint
    try:
        response = requests.get(
            f"{base_url}/api/status",
            timeout=REQUEST_TIMEOUT
        )
        if response.status_code == 200:
            data = response.json()
            service_info['version'] = data.get('version', 'unknown')
            if not data.get('auth', {}).get('enabled'):
                vulns.append('no_auth')
    except:
        pass
    
    # Check 3: Clawdbot web UI indicators
    try:
        response = requests.get(
            base_url,
            timeout=REQUEST_TIMEOUT
        )
        if response.status_code == 200:
            content = response.text.lower()
            # Check for Clawdbot-specific strings
            if 'clawdbot' in content or 'claude' in content:
                service_info['web_ui'] = True
                
                # Check for authentication
                if 'login' not in content and 'sign in' not in content:
                    vulns.append('no_auth')
    except:
        pass
    
    # Check 4: Gateway port (18789) specific checks
    if port == 18789:
        try:
            response = requests.get(
                f"http://{ip}:18789/health",
                timeout=REQUEST_TIMEOUT
            )
            if response.status_code == 200:
                service_info['gateway_direct'] = True
                vulns.append('gateway_exposed')
        except:
            pass
    
    # Check 5: Browser control port (18791)
    if port == 18791:
        try:
            response = requests.get(
                f"http://{ip}:18791/status",
                timeout=REQUEST_TIMEOUT
            )
            if response.status_code == 200:
                service_info['browser_control'] = True
                vulns.append('browser_control_exposed')
        except:
            pass
    
    is_clawdbot = bool(service_info)  # Any positive fingerprint match
    return is_clawdbot, vulns, service_info

def search_censys():
    """Query Censys API for Clawdbot installations with fingerprinting."""
    if not CENSYS_API_ID or not CENSYS_API_SECRET:
        logger.warning("Censys API not configured")
        return None
    
    results = []
    seen_ips = set()  # Avoid duplicates
    
    # Search queries for Clawdbot-related services
    queries = [
        {"query": "18789", "service": "Clawdbot Gateway"},
        {"query": "3000", "service": "Clawdbot Web UI"},
        {"query": "18791", "service": "Clawdbot Browser Control"},
    ]
    
    headers = {
        'Accept': 'application/json'
    }
    
    for search in queries:
        try:
            url = f"https://search.censys.io/api/v2/hosts/search?q={search['query']}&per_page=50"
            auth = (CENSYS_API_ID, CENSYS_API_SECRET)
            
            response = requests.get(url, headers=headers, auth=auth, timeout=15)
            
            logger.info(f"Censys query '{search['query']}': {response.status_code}")
            
            if response.status_code == 401:
                logger.error("Censys API authentication failed - check credentials")
                return None
                
            if response.status_code == 200:
                data = response.json()
                hits = data.get('result', {}).get('hits', [])
                logger.info(f"  Found {len(hits)} hosts with port {search['query']}")
                
                for hit in hits:
                    ip = hit.get('ip', 'unknown')
                    
                    if ip in seen_ips:
                        continue
                    seen_ips.add(ip)
                    
                    location = hit.get('location', {})
                    services = hit.get('services', [])
                    port = services[0].get('port', int(search['query'])) if services else int(search['query'])
                    
                    logger.info(f"  Fingerprinting {ip}:{port}...")
                    
                    # Active fingerprinting
                    is_clawdbot, vulns, service_info = fingerprint_clawdbot(ip, port)
                    
                    if not is_clawdbot:
                        logger.debug(f"    Skipping {ip}:{port} - fingerprint failed")
                        logger.debug(f"    Service info: {service_info}")
                        continue  # Skip non-Clawdbot services
                    
                    # Add fingerprinting-based vulnerabilities
                    if 'gateway' in service_info and port != 18789:
                        vulns.append('gateway_exposed')
                    
                    if 'browser_control' in service_info and port != 18791:
                        vulns.append('browser_control_exposed')
                    
                    # Create result entry
                    result = {
                        'ip': ip,
                        'port': port,
                        'risk_score': calculate_risk_score(vulns),
                        'location': {
                            'city': location.get('city', 'Unknown'),
                            'country_name': location.get('country', 'Unknown'),
                            'lat': location.get('latitude'),
                            'lng': location.get('longitude')
                        },
                        'vulns': vulns,
                        'service': search['service'],
                        'service_info': service_info,
                        'timestamp': datetime.now().isoformat(),
                        'fingerprint_method': 'active_verification'
                    }
                    results.append(result)
                    
        except Exception as e:
            logger.error(f"Censys search error for {search['query']}: {e}")
            continue
    
    return results

def run_background_scan():
    """Background task to run scans periodically."""
    logger.info("üîÑ Starting scheduled scan...")
    
    if not CENSYS_API_ID or not CENSYS_API_SECRET:
        logger.warning("Censys API not configured, skipping scan")
        return
    
    results = search_censys()
    
    if results is None:
        logger.error("Scan failed")
        return
    
    # Save results
    data_file = ensure_data_file()
    with open(data_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    logger.info(f"‚úÖ Scan complete. Found {len(results)} verified Clawdbot installations.")

# Initialize scheduler
scheduler = BackgroundScheduler()

@app.route('/')
def index():
    """Main dashboard."""
    results = load_results()
    
    for r in results:
        r['time_to_compromise'] = max(1, int((100 - r.get('risk_score', 50)) * 0.5))
    
    # Calculate chart data
    critical_count = sum(1 for r in results if r.get('risk_score', 0) > 85)
    high_count = sum(1 for r in results if 70 < r.get('risk_score', 0) <= 85)
    medium_count = sum(1 for r in results if 40 < r.get('risk_score', 0) <= 70)
    low_count = sum(1 for r in results if r.get('risk_score', 0) <= 40)
    
    # Get last scan time
    data_file = ensure_data_file()
    last_scan = None
    scan_count = 0
    if os.path.exists(data_file) and os.path.getsize(data_file) > 0:
        with open(data_file) as f:
            data = json.load(f)
            scan_count = len(data)
        last_scan = datetime.fromtimestamp(os.path.getmtime(data_file)).isoformat()
    
    stats = {
        'total': scan_count,
        'high_risk': sum(1 for r in results if r.get('risk_score', 0) > 70),
        'critical': critical_count,
        'avg_risk': sum(r.get('risk_score', 0) for r in results) / max(len(results), 1),
        'countries': len(set(r.get('location', {}).get('country_name', 'Unknown') for r in results)),
        'total_exposed': len(results) * random.randint(100, 10000),
        'attack_surface': len(results),
        # Chart data
        'risk_distribution': [critical_count, high_count, medium_count, low_count],
        'risk_labels': ['Critical', 'High', 'Medium', 'Low'],
        'api_connected': bool(CENSYS_API_ID),
        'last_scan': last_scan,
        'auto_refresh': True
    }
    
    return render_template('dashboard.html', results=results, stats=stats)

@app.route('/api/results')
def api_results():
    """JSON API for results."""
    results = load_results()
    for r in results:
        r['time_to_compromise'] = max(1, int((100 - r.get('risk_score', 50)) * 0.5))
    return jsonify(results)

@app.route('/api/stats')
def api_stats():
    """JSON API for stats."""
    results = load_results()
    critical_count = sum(1 for r in results if r.get('risk_score', 0) > 85)
    high_count = sum(1 for r in results if 70 < r.get('risk_score', 0) <= 85)
    medium_count = sum(1 for r in results if 40 < r.get('risk_score', 0) <= 70)
    low_count = sum(1 for r in results if r.get('risk_score', 0) <= 40)
    
    # Get last scan time
    data_file = ensure_data_file()
    last_scan = None
    scan_count = 0
    if os.path.exists(data_file) and os.path.getsize(data_file) > 0:
        with open(data_file) as f:
            data = json.load(f)
            scan_count = len(data)
        last_scan = datetime.fromtimestamp(os.path.getmtime(data_file)).isoformat()
    
    return jsonify({
        'total': scan_count,
        'high_risk': sum(1 for r in results if r.get('risk_score', 0) > 70),
        'critical': critical_count,
        'avg_risk': sum(r.get('risk_score', 0) for r in results) / max(len(results), 1),
        'countries': len(set(r.get('location', {}).get('country_name', 'Unknown') for r in results)),
        'total_exposed': len(results) * random.randint(100, 10000),
        'attack_surface': len(results),
        'risk_distribution': [critical_count, high_count, medium_count, low_count],
        'api_connected': bool(CENSYS_API_ID),
        'last_scan': last_scan,
        'auto_refresh': True
    })

@app.route('/api/demo/<ip>/<int:port>')
def api_demo(ip, port):
    """Generate demo attack simulation."""
    return jsonify({
        'target': f'{ip}:{port}',
        'timestamp': datetime.now().isoformat(),
        'vulnerabilities': [
            'No authentication required',
            'Exposed API endpoints',
            'Missing rate limiting',
            'No input validation'
        ],
        'exploit_time': random.randint(1, 30) / 100,
        'impact': 'CRITICAL',
        'commands': [
            f'curl http://{ip}:{port}/api/health',
            f'curl http://{ip}:{port}/api/messages',
            f'curl http://{ip}:{port}/api/config'
        ]
    })

@app.route('/api/scan', methods=['POST'])
def api_scan():
    """Trigger a new scan via Censys API with fingerprinting."""
    if not CENSYS_API_ID or not CENSYS_API_SECRET:
        return jsonify({
            'status': 'error',
            'message': 'Censys API not configured. Please set CENSYS_API_ID and CENSYS_API_SECRET.'
        }), 400
    
    results = search_censys()
    
    if results is None:
        return jsonify({
            'status': 'error',
            'message': 'Censys API request failed. Check credentials.'
        }), 500
    
    # Save results
    data_file = ensure_data_file()
    with open(data_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    return jsonify({
        'status': 'success',
        'message': f'Scan complete. Found {len(results)} verified Clawdbot installations.',
        'timestamp': datetime.now().isoformat(),
        'fingerprint_method': 'active_verification',
        'total_found': len(results)
    })

@app.route('/api/scan/debug', methods=['GET'])
def api_scan_debug():
    """Debug endpoint - shows raw Censys results without fingerprinting."""
    if not CENSYS_API_ID or not CENSYS_API_SECRET:
        return jsonify({
            'status': 'error',
            'message': 'Censys API not configured.'
        }), 400
    
    raw_results = []
    seen_ips = set()
    api_error = None
    
    queries = [
        {"query": "18789", "service": "Clawdbot Gateway"},
        {"query": "3000", "service": "Clawdbot Web UI"},
        {"query": "18791", "service": "Clawdbot Browser Control"},
    ]
    
    headers = {'Accept': 'application/json'}
    
    for search in queries:
        try:
            url = f"https://search.censys.io/api/v2/hosts/search?q={search['query']}&per_page=20"
            auth = (CENSYS_API_ID, CENSYS_API_SECRET)
            response = requests.get(url, headers=headers, auth=auth, timeout=15)
            
            if response.status_code == 401:
                api_error = "Censys API authentication failed (401)"
                continue
                
            if response.status_code == 200:
                data = response.json()
                hits = data.get('result', {}).get('hits', [])
                
                for hit in hits:
                    ip = hit.get('ip', 'unknown')
                    if ip in seen_ips:
                        continue
                    seen_ips.add(ip)
                    
                    location = hit.get('location', {})
                    services = hit.get('services', [])
                    port = services[0].get('port', int(search['query'])) if services else int(search['query'])
                    
                    raw_results.append({
                        'ip': ip,
                        'port': port,
                        'service': search['service'],
                        'location': {
                            'city': location.get('city', 'Unknown'),
                            'country': location.get('country', 'Unknown'),
                        },
                        'timestamp': datetime.now().isoformat()
                    })
                    
        except Exception as e:
            logger.error(f"Debug scan error: {e}")
    
    return jsonify({
        'status': 'error' if api_error else 'success',
        'api_error': api_error,
        'total_hosts': len(raw_results),
        'hosts': raw_results,
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/fingerprint/<ip>/<int:port>', methods=['GET'])
def api_fingerprint(ip, port):
    """Manually fingerprint a specific IP:port."""
    is_clawdbot, vulns, service_info = fingerprint_clawdbot(ip, port)
    
    return jsonify({
        'ip': ip,
        'port': port,
        'is_clawdbot': is_clawdbot,
        'vulnerabilities': vulns,
        'service_info': service_info,
        'risk_score': calculate_risk_score(vulns)
    })

@app.route('/api/refresh', methods=['POST'])
def api_refresh():
    """Trigger a new scan."""
    return jsonify({
        'status': 'success',
        'message': 'Scan triggered',
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/health')
def api_health():
    """Health check endpoint."""
    return jsonify({
        'status': 'ok',
        'scheduler_running': scheduler.running if 'scheduler' in dir() else False,
        'api_connected': bool(CENSYS_API_ID)
    })

# Security Intelligence Endpoints
@app.route('/api/security-intel')
def api_security_intel():
    """Return security intelligence data."""
    try:
        intel_file = 'static/data/security_intel.json'
        if os.path.exists(intel_file):
            with open(intel_file) as f:
                return jsonify(json.load(f))
        return jsonify({'error': 'No security intelligence data available'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/security-intel/refresh', methods=['POST'])
def refresh_security_intel():
    """Trigger security intelligence refresh."""
    try:
        import subprocess
        result = subprocess.run(
            ['python3', 'security_intel.py'],
            cwd=os.path.dirname(os.path.abspath(__file__)),
            capture_output=True,
            text=True,
            timeout=120
        )
        if result.returncode == 0:
            return jsonify({
                'status': 'success',
                'message': 'Security intelligence refreshed'
            })
        else:
            return jsonify({
                'status': 'error',
                'message': result.stderr
            }), 500
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/security-intel/summary')
def api_security_summary():
    """Quick summary endpoint for dashboard widgets."""
    try:
        intel_file = 'static/data/security_intel.json'
        if os.path.exists(intel_file):
            with open(intel_file) as f:
                data = json.load(f)
                return jsonify({
                    'total_discussions': data['summary']['total_discussions'],
                    'critical_count': data['summary']['critical_count'],
                    'high_count': data['summary']['high_count'],
                    'average_severity': data['summary']['average_severity'],
                    'top_issue': data['top_security_concerns'][0]['issue'] if data['top_security_concerns'] else None,
                    'generated': data['meta']['generated']
                })
        return jsonify({'error': 'No data available'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ============ SURF FORECAST ENDPOINTS ============

def get_multi_day_forecast(lat, lon, days=3):
    """Get 3-day forecast for all days."""
    headers = {
        'User-Agent': 'Ayali-WingFoil-Forecast/1.0'
    }
    
    # Get weather data (wind) for multiple days
    weather_url = "https://api.open-meteo.com/v1/forecast"
    weather_params = {
        'latitude': lat,
        'longitude': lon,
        'hourly': 'wind_speed_10m,wind_direction_10m',
        'timezone': 'auto',
        'forecast_days': days
    }
    
    try:
        weather_resp = requests.get(weather_url, params=weather_params, headers=headers, timeout=15)
        weather_resp.raise_for_status()
        weather_data = weather_resp.json()
        
        # Analyze each day
        times = weather_data['hourly'].get('time', [])
        wind_speeds = weather_data['hourly'].get('wind_speed_10m', [])
        
        daily_analysis = {}
        for i, time in enumerate(times):
            if i >= len(wind_speeds):
                break
            speed = wind_speeds[i]
            if speed is None:
                continue
            
            date = time[:10]
            hour = datetime.fromisoformat(time).hour
            
            if date not in daily_analysis:
                daily_analysis[date] = {'hours': [], 'good_hours': 0, 'max_speed': 0, 'min_speed': 100}
            
            daily_analysis[date]['hours'].append({'hour': hour, 'speed': speed})
            
            # Count good wing foil hours (10-40 km/h, 6 AM - 7 PM)
            if 10 <= speed <= 40 and 6 <= hour <= 19:
                daily_analysis[date]['good_hours'] += 1
            
            daily_analysis[date]['max_speed'] = max(daily_analysis[date]['max_speed'], speed)
            daily_analysis[date]['min_speed'] = min(daily_analysis[date]['min_speed'], speed)
        
        # Score and rank days
        days_ranked = []
        for date, data in daily_analysis.items():
            score = data['good_hours'] * 10  # More good hours = higher score
            
            # Bonus for optimal wind range
            avg_speed = sum(h['speed'] for h in data['hours']) / len(data['hours']) if data['hours'] else 0
            if 15 <= avg_speed <= 35:
                score += 20  # Perfect average
            
            days_ranked.append({
                'date': date,
                'good_hours': data['good_hours'],
                'max_speed': data['max_speed'],
                'min_speed': data['min_speed'],
                'score': score
            })
        
        # Sort by score
        days_ranked.sort(key=lambda x: x['score'], reverse=True)
        
        return {
            'daily': days_ranked,
            'source': 'Open-Meteo Weather API (free)',
            'updated': datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Multi-day forecast error: {e}")
        return None


def get_surf_forecast(lat, lon, days=1):
    """Fetch surf forecast from Open-Meteo APIs (Marine + Weather for wind)."""
    headers = {
        'User-Agent': 'Ayali-WingFoil-Forecast/1.0'
    }
    
    # Get marine data (waves)
    marine_url = "https://marine-api.open-meteo.com/v1/marine"
    marine_params = {
        'latitude': lat,
        'longitude': lon,
        'hourly': 'wave_height,wave_direction,wave_period,wind_wave_height',
        'timezone': 'auto',
        'forecast_days': days
    }
    
    # Get weather data (wind)
    weather_url = "https://api.open-meteo.com/v1/forecast"
    weather_params = {
        'latitude': lat,
        'longitude': lon,
        'hourly': 'wind_speed_10m,wind_direction_10m,wind_gusts_10m',
        'timezone': 'auto',
        'forecast_days': days
    }
    
    try:
        # Fetch marine data
        marine_resp = requests.get(marine_url, params=marine_params, headers=headers, timeout=15)
        marine_resp.raise_for_status()
        marine_data = marine_resp.json()
        
        # Fetch weather data
        weather_resp = requests.get(weather_url, params=weather_params, headers=headers, timeout=15)
        weather_resp.raise_for_status()
        weather_data = weather_resp.json()
        
        # Merge wind data into marine data
        marine_data['hourly']['wind_speed_10m'] = weather_data['hourly'].get('wind_speed_10m', [])
        marine_data['hourly']['wind_direction_10m'] = weather_data['hourly'].get('wind_direction_10m', [])
        marine_data['hourly']['wind_gusts_10m'] = weather_data['hourly'].get('wind_gusts_10m', [])
        
        # Add metadata
        marine_data['_source'] = 'Open-Meteo (Marine + Weather APIs, free)'
        marine_data['_updated'] = datetime.now().isoformat()
        
        return marine_data
    except requests.exceptions.Timeout:
        logger.error("Surf API timeout")
        return None
    except requests.exceptions.ConnectionError as e:
        logger.error(f"Surf API connection error: {e}")
        return None
    except Exception as e:
        logger.error(f"Surf API error: {e}")
        return None


def wind_direction_name(degrees):
    """Convert wind direction in degrees to compass name."""
    if degrees is None:
        return '--'
    dirs = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE', 
            'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']
    index = round(degrees / 22.5) % 16
    return dirs[index]


def generate_wind_summary(hourly_data):
    """Generate a paragraph describing wind conditions throughout the day."""
    times = hourly_data.get('time', [])
    wind_speeds = hourly_data.get('wind_speed_10m', [])
    
    if not wind_speeds:
        return "No wind data available."
    
    # Find periods (handle None values)
    periods = []
    for i, speed in enumerate(wind_speeds):
        if i >= len(times):
            break
        if speed is None:
            continue
        hour = datetime.fromisoformat(times[i]).hour
        periods.append({'hour': hour, 'speed': speed})
    
    if not periods:
        return "No wind data available."
    
    # Analyze
    light_wind = [(p['hour'], p['speed']) for p in periods if p['speed'] < 10]
    good_wind = [(p['hour'], p['speed']) for p in periods if 10 <= p['speed'] <= 40]
    strong_wind = [(p['hour'], p['speed']) for p in periods if p['speed'] > 40]
    
    summary_parts = []
    
    if good_wind:
        good_hours = [h for h, s in good_wind]
        start_hour = min(good_hours)
        end_hour = max(good_hours)
        summary_parts.append(f"üí® Good wing foil conditions ({start_hour}:00-{end_hour}:00) when wind is 10-40 km/h.")
    
    if light_wind:
        light_hours = [h for h, s in light_wind]
        summary_parts.append(f"üïäÔ∏è Light winds under 10 km/h at {', '.join(str(h) for h in light_hours)} ‚Äî too light for foiling.")
    
    if strong_wind:
        strong_hours = [h for h, s in strong_wind]
        summary_parts.append(f"‚ö†Ô∏è Strong winds over 40 km/h at {', '.join(str(h) for h in strong_hours)} ‚Äî advanced conditions only.")
    
    if not summary_parts:
        return "Variable wind conditions today. Check the hourly table for details."
    
    return ' '.join(summary_parts)


def analyze_surf_conditions(hourly_data, target_hour_start=6, target_hour_end=10):
    """Find best surf time based on conditions."""
    times = hourly_data.get('time', [])
    wave_heights = hourly_data.get('wave_height', [])
    wave_dirs = hourly_data.get('wave_direction', [])
    wind_speeds = hourly_data.get('wind_speed_10m', [])
    wind_dirs = hourly_data.get('wind_direction_10m', [])
    wave_periods = hourly_data.get('wave_period', [])
    
    best_hours = []
    
    for i, time in enumerate(times):
        hour = datetime.fromisoformat(time).hour
        if hour < target_hour_start or hour >= target_hour_end:
            continue
        
        wave_height = wave_heights[i] if i < len(wave_heights) and wave_heights[i] is not None else 0
        wind_speed = wind_speeds[i] if i < len(wind_speeds) and wind_speeds[i] is not None else 0
        wave_period = wave_periods[i] if i < len(wave_periods) and wave_periods[i] is not None else 0
        
        # WING FOIL SCORING (wind-focused, low waves preferred)
        score = 0
        
        # Wind: WING FOIL NEEDS 15-40 km/h (CRITICAL)
        if 15 <= wind_speed <= 40:
            # Sweet spot for wing foil
            if 20 <= wind_speed <= 35:
                score += 50  # Perfect!
            else:
                score += 40  # Good
        elif 10 <= wind_speed < 15:
            score += 20  # Light but possible
        elif wind_speed < 10:
            score -= 30  # Too light - no lift
        else:  # wind_speed > 40
            score -= 20  # Too strong - dangerous
        
        # Waves: LOWER is better for wing foil (stability)
        if wave_height <= 0.3:
            score += 25  # Perfectly calm
        elif wave_height <= 0.6:
            score += 15  # Manageable
        elif wave_height <= 1.0:
            score += 0  # OK
        else:  # wave_height > 1.0
            score -= 30  # Too choppy - destabilizes foil
        
        # Wave period: longer = smoother rides
        if wave_period >= 10:
            score += 10
        elif wave_period >= 7:
            score += 5
        
        best_hours.append({
            'time': time,
            'hour': hour,
            'wave_height': wave_height,
            'wave_direction': wave_dirs[i] if i < len(wave_dirs) else None,
            'wind_speed': wind_speed,
            'wind_direction': wind_dirs[i] if i < len(wind_dirs) else None,
            'wave_period': wave_period,
            'score': score
        })
    
    # Sort by score
    best_hours.sort(key=lambda x: x['score'], reverse=True)
    return best_hours


@app.route('/surf')
def surf_dashboard():
    """Surf forecast dashboard."""
    return render_template('surf.html')


@app.route('/api/surf/forecast')
def api_surf_forecast():
    """Get surf forecast for a location."""
    lat = request.args.get('lat', type=float)
    lon = request.args.get('lon', type=float)
    spot_name = request.args.get('spot', 'Unknown Spot')
    
    if lat is None or lon is None:
        return jsonify({'error': 'Missing lat/lon parameters'}), 400
    
    if lat < -90 or lat > 90 or lon < -180 or lon > 180:
        return jsonify({'error': 'Invalid coordinates'}), 400
    
    forecast = get_surf_forecast(lat, lon)
    
    if not forecast:
        # Try single API as fallback
        try:
            headers = {'User-Agent': 'Ayali-WingFoil-Forecast/1.0'}
            weather_url = "https://api.open-meteo.com/v1/forecast"
            weather_params = {
                'latitude': lat,
                'longitude': lon,
                'hourly': 'wind_speed_10m,wind_direction_10m,wave_height',
                'timezone': 'auto',
                'forecast_days': 1
            }
            weather_resp = requests.get(weather_url, params=weather_params, headers=headers, timeout=30)
            weather_resp.raise_for_status()
            weather_data = weather_resp.json()
            
            # Use weather data directly
            forecast = {
                'hourly': {
                    'time': weather_data.get('hourly', {}).get('time', []),
                    'wave_height': weather_data.get('hourly', {}).get('wave_height', []),
                    'wind_speed_10m': weather_data.get('hourly', {}).get('wind_speed_10m', []),
                    'wind_direction_10m': weather_data.get('hourly', {}).get('wind_direction_10m', []),
                },
                '_source': 'Open-Meteo Weather API (fallback)',
                '_updated': datetime.now().isoformat()
            }
        except Exception as fallback_error:
            logger.error(f"Fallback also failed: {fallback_error}")
            return jsonify({'error': f'Failed to fetch forecast. Debug: {str(fallback_error)[:100]}'}), 500
    
    # Extract metadata
    source = forecast.get('_source', 'Open-Meteo Marine API')
    updated = forecast.get('_updated', datetime.now().isoformat())
    timezone = forecast.get('timezone', 'UTC')
    
    # Analyze for morning surf (6-10 AM)
    hourly = forecast.get('hourly', {})
    morning_surf = analyze_surf_conditions(hourly, target_hour_start=6, target_hour_end=10)
    
    # Get ALL hourly wind data for the day
    all_hours = []
    times = hourly.get('time', [])
    wind_speeds = hourly.get('wind_speed_10m', [])
    wind_dirs = hourly.get('wind_direction_10m', [])
    
    for i, time in enumerate(times):
        hour = datetime.fromisoformat(time).hour
        speed = wind_speeds[i] if i < len(wind_speeds) else None
        direction = wind_dirs[i] if i < len(wind_dirs) else None
        
        all_hours.append({
            'time': time,
            'hour': hour,
            'wind_speed': speed,
            'wind_direction': direction,
            'wind_dir_name': wind_direction_name(direction)
        })
    
    # Generate wind summary
    wind_summary = generate_wind_summary(hourly)
    
    # Get best time
    best_time = None
    if morning_surf:
        best = morning_surf[0]
        best_time = {
            'time': best['time'][11:16],
            'wave_height': best['wave_height'],
            'wind_speed': best['wind_speed'],
            'wind_direction': best['wind_direction'],
            'wind_dir_name': wind_direction_name(best.get('wind_direction')),
            'score': best['score'],
            'conditions': 'üî• Great' if best['score'] > 40 else ('‚úÖ Good' if best['score'] > 20 else ('‚ö†Ô∏è Fair' if best['score'] > 0 else '‚ùå Poor'))
        }
    
    return jsonify({
        'spot': spot_name,
        'location': {'lat': lat, 'lon': lon},
        'source': source,
        'updated': updated,
        'timezone': timezone,
        'morning_surf': morning_surf[:5] if morning_surf else [],
        'all_hours': all_hours,
        'best_time': best_time,
        'wind_summary': wind_summary,
        'generated': datetime.now().isoformat()
    })


@app.route('/api/surf/conditions')
def api_surf_conditions():
    """Get detailed surf conditions."""
    lat = request.args.get('lat', 32.0853, type=float)
    lon = request.args.get('lon', 34.7818, type=float)
    
    forecast = get_surf_forecast(lat, lon, days=2)
    
    if not forecast:
        return jsonify({'error': 'Failed to fetch conditions'}), 500
    
    return jsonify({
        'hourly': forecast.get('hourly', {}),
        'timezone': forecast.get('timezone'),
        'generated': datetime.now().isoformat()
    })


@app.route('/api/surf/multi-day')
def api_surf_multi_day():
    """Get 3-day surf forecast comparison."""
    lat = request.args.get('lat', type=float)
    lon = request.args.get('lon', type=float)
    
    if lat is None or lon is None:
        return jsonify({'error': 'Missing lat/lon parameters'}), 400
    
    if lat < -90 or lat > 90 or lon < -180 or lon > 180:
        return jsonify({'error': 'Invalid coordinates'}), 400
    
    forecast = get_multi_day_forecast(lat, lon, days=3)
    
    if not forecast:
        return jsonify({'error': 'Failed to fetch multi-day forecast'}), 500
    
    # Add recommendations
    if forecast['daily']:
        best_day = forecast['daily'][0]
        recommendations = []
        
        for day in forecast['daily'][:3]:
            date = datetime.strptime(day['date'], '%Y-%m-%d').strftime('%A, %b %d')
            
            if day['good_hours'] >= 6:
                recommendations.append({
                    'date': date,
                    'rating': 'üî• Excellent',
                    'message': f"{day['good_hours']} hours of good wind (10-40 km/h)",
                    'best_for': 'Wing foiling'
                })
            elif day['good_hours'] >= 3:
                recommendations.append({
                    'date': date,
                    'rating': '‚úÖ Good',
                    'message': f"{day['good_hours']} hours of good wind",
                    'best_for': 'Wing foiling (short session)'
                })
            elif day['good_hours'] >= 1:
                recommendations.append({
                    'date': date,
                    'rating': '‚ö†Ô∏è Fair',
                    'message': f"Only {day['good_hours']} good hour - check timing",
                    'best_for': 'Quick session'
                })
            else:
                recommendations.append({
                    'date': date,
                    'rating': '‚ùå Poor',
                    'message': 'No good wing foil conditions',
                    'best_for': 'Skip'
                })
    
    return jsonify({
        'source': forecast['source'],
        'updated': forecast['updated'],
        'days': forecast['daily'],
        'recommendations': recommendations if forecast['daily'] else [],
        'best_day': {
            'date': datetime.strptime(best_day['date'], '%Y-%m-%d').strftime('%A, %b %d') if best_day else None,
            'rating': 'üî• Best Day' if best_day and best_day['score'] > 40 else ('‚úÖ Good Day' if best_day else None),
            'good_hours': best_day['good_hours'] if best_day else 0
        },
        'generated': datetime.now().isoformat()
    })


if __name__ == '__main__':
    print("üöÄ Dashboard starting at http://localhost:5000")
    print("üéØ Clawdbot Security Intelligence Dashboard")
    print("üõ°Ô∏è  Security Intelligence: Active (web, X, blogs)")
    print("üîç Fingerprinting: Active verification enabled")
    print("‚è∞ Auto-scan: Every hour")
    
    # Start background scheduler
    if CENSYS_API_ID and CENSYS_API_SECRET:
        scheduler.add_job(
            run_background_scan,
            trigger=IntervalTrigger(hours=1),
            id='hourly_scan',
            name='Hourly Clawdbot scan',
            replace_existing=True
        )
        scheduler.start()
        print("‚úÖ Background scheduler started")
    else:
        # Still start without external API
        scheduler.start()
        print("‚úÖ Background scheduler started (no external API)")
    
    app.run(debug=True, host='0.0.0.0', port=5000)
